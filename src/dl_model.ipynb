{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dO4FnbVjYluf",
   "metadata": {
    "id": "dO4FnbVjYluf"
   },
   "source": [
    "# DL Model\n",
    "This notebook defines, trains, and validates the DL model.\n",
    "\n",
    "It first loads following data files generated from pre-processing steps. Input and output data Tensors are created and pushed to GPU memory. Then, model is defined, trained, and validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599f50e",
   "metadata": {
    "id": "4599f50e"
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import pickle\n",
    "import time\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8964d2",
   "metadata": {
    "id": "de8964d2"
   },
   "outputs": [],
   "source": [
    "# Set seed for random generators\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924be7d",
   "metadata": {
    "id": "3924be7d"
   },
   "outputs": [],
   "source": [
    "# Set the device type as cpu or cuda depending upon the execution environment.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6DKWE5tho7U",
   "metadata": {
    "id": "s6DKWE5tho7U"
   },
   "outputs": [],
   "source": [
    "# Clone git repo containing all the pre-processed data files. THIS IS ONLY NEEDED IN CLOUD ENVIRONMENT.\n",
    "\n",
    "!git clone https://github.com/manuv3/cs598-dl-project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fVmreShG6XXZ",
   "metadata": {
    "id": "fVmreShG6XXZ"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './cs598-dl-project/data'\n",
    "\n",
    "# USE BELOW FOR LOCAL TESTING\n",
    "# DATA_DIR = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ecd213",
   "metadata": {
    "id": "66ecd213"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Import the \"codes\" DataFrame, with HADM_ID (Hospitalization ID) as index and multi-hot encoding of \n",
    "ICD9-codes (booleans) as columns. Its dimensions are a 52691 rows Ã— 6984 columns. So, we have 6984 ICD9 codes.\n",
    "'''\n",
    "\n",
    "codes = pd.read_pickle(DATA_DIR + '/diagnoses.pkl.gz')\n",
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c6d78",
   "metadata": {
    "id": "576c6d78"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Split the HADM_IDs (hospitalization IDs) into train-test in 90:10 ratio. Two lists are generated:\n",
    "    - hadm_ids_train\n",
    "    - hadm_ids_test\n",
    "'''\n",
    "\n",
    "hadm_ids_train, hadm_ids_test = train_test_split(codes.index.tolist(), test_size = 0.10, random_state=seed)\n",
    "print(hadm_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1de3f6",
   "metadata": {
    "id": "5e1de3f6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load the Doc2Vec embeddings for discharge summary reports, generated during pre-processing step. The data is in \n",
    "Gensim KeyedVector format.\n",
    "'''\n",
    "\n",
    "dv = KeyedVectors.load(DATA_DIR + '/dv.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71e938",
   "metadata": {
    "id": "2d71e938"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load the Word2Vec embeddings of all the words in vocabulary of the whole corpus, generated during the \n",
    "pre-processing step. This data is in Gensim KeyedVector format.\n",
    "'''\n",
    "\n",
    "wv = KeyedVectors.load(DATA_DIR + '/wv.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KyuZNasTQ_Dm",
   "metadata": {
    "id": "KyuZNasTQ_Dm"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load the dictionary mapping HADM_ID with a tokenized document. These tokens are basically the list of words \n",
    "belonging to the corresponding Discharge summary report.\n",
    "'''\n",
    "\n",
    "with bz2.open(DATA_DIR + '/tokens_map.pkl.bz2', 'rb') as handle:\n",
    "  tokens_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7f611",
   "metadata": {
    "id": "d8b7f611"
   },
   "outputs": [],
   "source": [
    "# how many samples per batch to load\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a0882",
   "metadata": {
    "id": "710a0882"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Define the implementation of PyTorch Dataset. This is very light-weight, as all the data tensors (dv_train, \n",
    "dv_test, tokens_train, tokens_test, and codes_train) have already been pushed to GPU memory. So they can be \n",
    "referenced by HADM_ID index. This dataset simply returns the input index as the data in __getitem()__ method, which \n",
    "will be used during model training to access the input and output data from data tensors.\n",
    "'''\n",
    "\n",
    "class DocumentsDataset(Dataset):\n",
    "    def __init__(self, hadm_ids):\n",
    "        super(DocumentsDataset).__init__()\n",
    "        self.hadm_ids = hadm_ids\n",
    "    def __len__(self):\n",
    "        return len(self.hadm_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        hadm_id = self.hadm_ids[idx]\n",
    "        tokens = tokens_dict[hadm_id]\n",
    "        word_vecs = torch.Tensor(wv.__getitem__(tokens))\n",
    "        x_cnn = torch.zeros((700, 100))\n",
    "        x_cnn[0:word_vecs.shape[0]] = word_vecs\n",
    "        x_d2v = torch.Tensor(dv[str(hadm_id)].tolist())\n",
    "        y = torch.tensor(codes.loc[hadm_id].to_numpy())\n",
    "        return x_d2v, x_cnn, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476af18",
   "metadata": {
    "id": "d476af18"
   },
   "outputs": [],
   "source": [
    "# prepare dataloaders\n",
    "train_loader = DataLoader(DocumentsDataset(hadm_ids_train), batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(DocumentsDataset(hadm_ids_test), batch_size = batch_size)\n",
    "\n",
    "print(\"# of train batches:\", len(train_loader))\n",
    "print(\"# of val batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d6695",
   "metadata": {
    "id": "447d6695"
   },
   "source": [
    "## Create DL Model\n",
    "\n",
    "The model is a DL network with two \"logical\" components:\n",
    "- **Encoder** to generate document embeddings: The function of this component is to generate effective fixed-length embedding for a given discharge summary document.This component consists of two \"logical\" sub-components:\n",
    "        - D2V: This sub-component first trains (as pre-processing step) Doc2Vec model to learn input document vectors of length `128`, in an unsupervised way. It then fine tunes this vector,using a fully connected layer of `64` neurons, followed by a non-linear activation like sigmoid. This fine-tune layer is trained in supervised way.\n",
    "        - CNN: This sub-component trains a Word2Vec model as pre-processing step to build word vectors for the whole vocabulary of the collective corpus of documents. For each document, all the vectors corresponding to the contained words, are concatenated, to represent the given document. These document vectors are used as input to the CNN sub-component. This sub-component actually comprises of 3 single-layer multi-channel CNN models. Three CNN models correspond to 3 kernel sizes (of 3, 4, and 5 words)) with 64 output channels each. For CNN layer in each model is followed by a MaxPool layer to perform temporal pooling. The outputs of each of these CNN models are concatenated to generate the output vector per document of size `192 (3 models * 64 channels each)`. \n",
    "\n",
    "The ouput vectors from the two sub-components (D2V and CNN) are concatenated to produce the final vector for each document in the batch. Ths final vector size is `256 (64 from DNN + 192 from CNN)`.\n",
    "\n",
    "- **Classifier** to perform multi-label classification of ICD-9 codes. This component consists of:\n",
    "    - Dropout layer: The document vector generated by encoder component is regularized by stochastically dropping different dimensions.\n",
    "\t- Fully connected layer with sigmoid activation: This layer generates the final output of size `6984` (total number of ICD-9 codes)}. Each dimension (representing an ICD-9 code) is assigned a probability by sigmoid activation.\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1oKffyBVaQxrDIqXc-ulP-AYSkBh_FnoO\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d57a5",
   "metadata": {
    "id": "772d57a5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Define the model class which represents the D2V sub-component that uses single fully connected layer to fine-tune \n",
    "the Doc2Vec embeddings. This representation is passed through a Dropout layer to perform regularization, and the output is the \n",
    "vector representing the input document.\n",
    "'''\n",
    "\n",
    "class D2V(nn.Module):\n",
    "    def __init__(self, dropout = 0.20):\n",
    "        super(D2V, self).__init__()\n",
    "        self.fc = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "    def forward(self, x):\n",
    "        y = self.dropout(F.relu(self.fc(x)))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbede23a",
   "metadata": {
    "id": "dbede23a"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Define the model class which is the building block of the CNN sub-component containining a single layer of \n",
    "multi-channel CNN kernel, activation function, and max-pooling layer.\n",
    "'''\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, kernel_size, in_channels = 1, out_channels = 64):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, (kernel_size, 100))\n",
    "        self.pool = nn.MaxPool2d((700 - kernel_size + 1,1))\n",
    "    def forward(self, x):\n",
    "        y = self.pool(F.relu(self.conv(x))).squeeze()\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae0791",
   "metadata": {
    "id": "fdae0791"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Define the model class for CNN sub-component. This component concatenates the output of 3 CNN components (described \n",
    "previously), each corresponding to different kernel size (3, 4, and 5 words). Its input is \"concatenated\" Word2Vec \n",
    "embeddings of all words within a document, which it passes to the three CNN components parallely, and then combines \n",
    "their output. This representation is passed through a Dropout layer to perform regularization, and the output is the \n",
    "vector representing the input document.\n",
    "'''\n",
    "\n",
    "class CNN_COMBINED(nn.Module):\n",
    "    def __init__(self, dropout = 0.20):\n",
    "        super(CNN_COMBINED, self).__init__()\n",
    "        self.conv_3 = CNN(3)\n",
    "        self.conv_4 = CNN(4)\n",
    "        self.conv_5 = CNN(5)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        return self.dropout(torch.cat((self.conv_3(x), self.conv_4(x), self.conv_5(x)), dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88334e11",
   "metadata": {
    "id": "88334e11"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Define the class for the main model, which uses both from D2V and CNN_COMBINED components, in the Encoder layer.\n",
    "'''\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout_d2v, dropout_cnn):\n",
    "        super(Net, self).__init__()\n",
    "        self.d2v = D2V(dropout = dropout_d2v)\n",
    "        self.cnn = CNN_COMBINED(dropout = dropout_cnn)\n",
    "        self.fc2 = nn.Linear(256, 6984)\n",
    "\n",
    "    def forward(self, x_d2v, x_cnn):\n",
    "        y_d2v = self.d2v(x_d2v)\n",
    "        y_cnn = self.cnn(x_cnn)\n",
    "        y = torch.sigmoid(self.fc2(torch.cat((y_d2v, y_cnn), dim = 1)))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd300fb",
   "metadata": {
    "id": "fbd300fb"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Define the class for the cnn-only ablation model, which uses only the CNN_COMBINED component in the Encoder layer. \n",
    "'''\n",
    "\n",
    "class Net_CNN(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(Net_CNN, self).__init__()\n",
    "        self.cnn = CNN_COMBINED(dropout)\n",
    "        self.fc2 = nn.Linear(192, 6984)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc2(self.cnn(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qGYv4g1tSPHZ",
   "metadata": {
    "id": "qGYv4g1tSPHZ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Define the class for the d2v-only ablation model, which uses only the D2V component in the Encoder layer. \n",
    "'''\n",
    "\n",
    "class Net_D2V(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(Net_D2V, self).__init__()\n",
    "        self.d2v = D2V(dropout = dropout)\n",
    "        self.fc = nn.Linear(64, 6984)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc(self.d2v(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k1EACzcrMlvT",
   "metadata": {
    "id": "k1EACzcrMlvT"
   },
   "source": [
    "## CNN + Attention Model (not part of original paper)\n",
    "\n",
    "This model is to study the impact of attention over plain CNN, to demonstrate the effectiveness of leveraging attention instead of max-pooling of\n",
    "CNN hidden states.\n",
    "\n",
    "The archiecture of this model consists of a single layer multi-channel 1D CNN, an attention mechanism, and finally, the classification component consisting of a fully connected layer with a Sigmoid classifier.\n",
    "\n",
    "The intuition behind this is that the originally proposed model uses Convolution with Max Pooling, which ignores contribution of all group of tokens except the one with max value. We may be able to do better by adding the weighted contribution of all groups of tokens (generated by convolution).\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?id=1pF_ZXTsraff0yXY5pYzww5FMnEtbeilk\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z1B3AK30D9vl",
   "metadata": {
    "id": "Z1B3AK30D9vl"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Define the class for the cnn + attention model.\n",
    "'''\n",
    "\n",
    "class Net_CNN_Attention(nn.Module):\n",
    "    def __init__(self, kernel_size, dropout):\n",
    "        super(Net_CNN_Attention, self).__init__()\n",
    "        self.conv = nn.Conv1d(100, 50, kernel_size)\n",
    "        self.att = nn.Linear(50, 6984, bias = False)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.fc = nn.Linear(50, 1)\n",
    "    def forward(self, x):\n",
    "        x = x.permute((0, 2, 1))\n",
    "        y = torch.relu(self.conv(x))\n",
    "        # apply attention\n",
    "        alpha = F.softmax(self.att.weight.matmul(y), dim=2)\n",
    "        # compute output by matrix multiplication of attention matrix with internal state\n",
    "        y = alpha.matmul(y.permute(0, 2, 1))\n",
    "        y = self.dropout(y)\n",
    "        y = torch.sigmoid(self.fc(y)).squeeze()\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5882723c",
   "metadata": {
    "id": "5882723c"
   },
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "def classification_metrics(Y_pred, Y_true):\n",
    "    \"\"\"\n",
    "    Calculate peformance metrics using scikit-learn.\n",
    "    \n",
    "    Arguments:\n",
    "        Y_pred: Long dtype Tensor of output values for the test set batch, as predicted by model.\n",
    "        Y_true: Long dtype Tensor of true values in the test-set batch.\n",
    "        \n",
    "    Outputs:\n",
    "        precision: overall micro-averaged precision score\n",
    "        recall: overall micro-averaged recall score\n",
    "        f1: overall micro-averaged f1 score\n",
    "        \n",
    "    REFERENCE: checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\"\"\"\n",
    "    \n",
    "    precision, recall, f1score = precision_score(Y_true, Y_pred, average = 'micro'), \\\n",
    "                                           recall_score(Y_true, Y_pred, average = 'micro'), \\\n",
    "                                           f1_score(Y_true, Y_pred, average = 'micro')\n",
    "    return precision, recall, f1score\n",
    "\n",
    "\n",
    "def evaluate(model, loader, threshold, only_cnn = False, only_d2v = False):\n",
    "    \"\"\"\n",
    "    Evaluate the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: Trained model of type nn.Module\n",
    "        loader: Test DataLoader\n",
    "        \n",
    "    Outputs:\n",
    "        precision: overall micro-averaged precision score\n",
    "        recall: overall micro-averaged recall score\n",
    "        f1: overall micro-averaged f1 score\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_y_true = torch.LongTensor()\n",
    "    all_y_pred = torch.LongTensor()\n",
    "    for x_d2v,x_cnn, y in loader:\n",
    "        if not only_cnn:\n",
    "          x_d2v = x_d2v.to(device)\n",
    "        if not only_d2v:\n",
    "          x_cnn = x_cnn.to(device)\n",
    "        if only_d2v:\n",
    "          y_hat = model(x_d2v)\n",
    "        elif only_cnn:\n",
    "          y_hat = model(x_cnn)\n",
    "        else:\n",
    "          y_hat = model(x_d2v, x_cnn)\n",
    "        y_pred = y_hat.detach().to('cpu').apply_(lambda x: 1 if x > threshold else 0)\n",
    "        all_y_true = torch.cat((all_y_true, y.long()), dim=0)\n",
    "        all_y_pred = torch.cat((all_y_pred,  y_pred.to('cpu').long()), dim=0)\n",
    "        \n",
    "    precision, recall, f1 = classification_metrics(all_y_pred.detach().numpy(), all_y_true.detach().numpy())\n",
    "    print(f\"precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}\")\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tmF8n-x4v5el",
   "metadata": {
    "id": "tmF8n-x4v5el"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, name, train_loader, max_epochs, threshold, only_cnn = False, only_d2v = False, checkpoint = False):\n",
    "  \"\"\"\n",
    "  Train and evaluate the model.\n",
    "\n",
    "  Arguments:\n",
    "      model: Trained model of type nn.Module\n",
    "      train_loader: Training dataloader of type torch.utils.data.DataLoader\n",
    "      \n",
    "  Outputs:\n",
    "      No output\n",
    "  \"\"\"\n",
    "  \n",
    "  epoch = 0\n",
    "  while epoch < max_epochs:\n",
    "    # prep model for training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x_d2v, x_cnn, y in train_loader:\n",
    "        if not only_cnn:\n",
    "          x_d2v = x_d2v.to(device)\n",
    "        if not only_d2v:\n",
    "          x_cnn = x_cnn.to(device)\n",
    "        y = y.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if only_d2v:\n",
    "          y_hat = model(x_d2v)\n",
    "        elif only_cnn:\n",
    "          y_hat = model(x_cnn)\n",
    "        else:\n",
    "          y_hat = model(x_d2v, x_cnn)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch: {} done!'.format(epoch))\n",
    "    if epoch % 2 == 0:\n",
    "        if checkpoint:\n",
    "            save_checkpoint(model, name + '-' + str(epoch) + '.pth')\n",
    "        # Evaluate the model\n",
    "        evaluate(model, test_loader, threshold, only_cnn, only_d2v)\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mH7ZsUOgESSQ",
   "metadata": {
    "id": "mH7ZsUOgESSQ"
   },
   "outputs": [],
   "source": [
    "# Save model internal state as intermediate checkpoint\n",
    "\n",
    "# Mount the google drive at 'drive' directory in the colab virtual machine.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('drive')\n",
    "\n",
    "# Define variable to point to the project directory in google drive.\n",
    "CHECKPOINT_DIR = 'drive/My Drive/cs598-dl/checkpoints/'\n",
    "\n",
    "# For Local testing\n",
    "# CHECKPOINT_DIR = '../checkpoints/'\n",
    "\n",
    "def save_checkpoint(model, name):\n",
    "    torch.save(model.state_dict(), CHECKPOINT_DIR + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CA6nJKsYBzJ9",
   "metadata": {
    "id": "CA6nJKsYBzJ9"
   },
   "source": [
    "## Train and evaluate main model\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "- MAX_EPOCHS\n",
    "- CLASSIFICATION_THRESHOLD\n",
    "- DROPOUT_D2V\n",
    "- DROPOUT_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gjxd_NEc3u5J",
   "metadata": {
    "id": "Gjxd_NEc3u5J"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Train and evaluate main model\n",
    "'''\n",
    "# Hyperparameters\n",
    "MAX_EPOCHS = 20\n",
    "CLASSIFICATION_THRESHOLD = 0.20\n",
    "DROPOUT_D2V = 0.30\n",
    "DROPOUT_CNN = 0.20\n",
    "\n",
    "# Define the model\n",
    "main_model = Net(DROPOUT_D2V, DROPOUT_CNN)\n",
    "\n",
    "# Move to GPU\n",
    "main_model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer for back-propagation.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(main_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train and evaluate\n",
    "sta = time.time()\n",
    "train_and_evaluate(model = main_model, \n",
    "                   name = 'main_model', \n",
    "                   train_loader = train_loader, \n",
    "                   max_epochs = MAX_EPOCHS, \n",
    "                   threshold = CLASSIFICATION_THRESHOLD, \n",
    "                   checkpoint = False)\n",
    "end = time.time()\n",
    "print('Time taken in training and validating main model:' + str(end - sta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O9Fxu7jm9f4X",
   "metadata": {
    "id": "O9Fxu7jm9f4X"
   },
   "source": [
    "## Train and evaluate cnn-only model (ablation)\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "- MAX_EPOCHS\n",
    "- CLASSIFICATION_THRESHOLD\n",
    "- DROPOUT_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423tB3Ai4bY6",
   "metadata": {
    "id": "423tB3Ai4bY6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Train and evaluate cnn-only model (ablation)\n",
    "'''\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_EPOCHS = 15\n",
    "CLASSIFICATION_THRESHOLD = 0.20\n",
    "DROPOUT_CNN = 0.20\n",
    "\n",
    "# Define the model\n",
    "cnn_only_model = Net_CNN(DROPOUT_CNN)\n",
    "\n",
    "# Move to GPU\n",
    "cnn_only_model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer for back-propagation.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(cnn_only_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train and evaluate\n",
    "sta = time.time()\n",
    "train_and_evaluate(model = cnn_only_model, \n",
    "                   name = 'cnn_only_model', \n",
    "                   train_loader = train_loader, \n",
    "                   max_epochs = MAX_EPOCHS, \n",
    "                   threshold = CLASSIFICATION_THRESHOLD, \n",
    "                   only_cnn = True, \n",
    "                   checkpoint = False)\n",
    "end = time.time()\n",
    "print('Time taken in training and validating cnn-only model:' + str(end - sta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sw-OUuiR9E_Y",
   "metadata": {
    "id": "sw-OUuiR9E_Y"
   },
   "source": [
    "## Train and evaluate d2v-only model (ablation)\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "- MAX_EPOCHS\n",
    "- CLASSIFICATION_THRESHOLD\n",
    "- DROPOUT_D2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95lQTCks7ggG",
   "metadata": {
    "id": "95lQTCks7ggG"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Train and evaluate d2v-only model (ablation)\n",
    "'''\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_EPOCHS = 15\n",
    "CLASSIFICATION_THRESHOLD = 0.18\n",
    "DROPOUT_D2V = 0.10\n",
    "\n",
    "# Define the model\n",
    "d2v_only_model = Net_D2V(DROPOUT_D2V)\n",
    "\n",
    "# Move to GPU\n",
    "d2v_only_model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer for back-propagation.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(d2v_only_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train and evaluate\n",
    "sta = time.time()\n",
    "train_and_evaluate(model = d2v_only_model, \n",
    "                   name = 'd2v_only_model', \n",
    "                   train_loader = train_loader, \n",
    "                   max_epochs = MAX_EPOCHS, \n",
    "                   threshold = CLASSIFICATION_THRESHOLD, \n",
    "                   only_d2v = True, \n",
    "                   checkpoint = False)\n",
    "end = time.time()\n",
    "print('Time taken in training and validating d2v-only model:' + str(end - sta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dvCQiXuf_ynT",
   "metadata": {
    "id": "dvCQiXuf_ynT"
   },
   "source": [
    "## Train and evaluate cnn + attention model (additional model)\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "- MAX_EPOCHS\n",
    "- CLASSIFICATION_THRESHOLD\n",
    "- DROPOUT_CNN\n",
    "- KERNEL_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UqQCKJOGAo11",
   "metadata": {
    "id": "UqQCKJOGAo11"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Train and evaluate cnn + attention model (additional model)\n",
    "'''\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_EPOCHS = 20\n",
    "CLASSIFICATION_THRESHOLD = 0.30\n",
    "DROPOUT_CNN = 0.10\n",
    "KERNEL_SIZE = 5\n",
    "\n",
    "# Define the model\n",
    "cnn_attention_model = Net_CNN_Attention(kernel_size = KERNEL_SIZE, dropout = DROPOUT_CNN)\n",
    "\n",
    "# Move to GPU\n",
    "cnn_attention_model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer for back-propagation.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(cnn_attention_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train and evaluate\n",
    "sta = time.time()\n",
    "train_and_evaluate(model = cnn_attention_model, \n",
    "                   name = 'cnn_attention_model', \n",
    "                   train_loader = train_loader, \n",
    "                   max_epochs = MAX_EPOCHS, \n",
    "                   threshold = CLASSIFICATION_THRESHOLD, \n",
    "                   only_cnn = True, \n",
    "                   checkpoint = False)\n",
    "end = time.time()\n",
    "print('Time taken in training and validating cnn-with-attention model:' + str(end - sta))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
